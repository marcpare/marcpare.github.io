 {% extends "base.html" %}

{% block content %}

<div class="mx-auto w-320 ring-1 ring-zinc-300/20 px-8">

    <div class="text-white py-4 flex items-center">

        <img class="inline-block"src="{{ url_for('static', filename='me-pixel-32.png') }}" width="32" /><span class="inline-block px-3 text-zinc-400">/</span></span><span class="inline-block">ai-privacy-engineer</span><span class="inline-block px-3 text-zinc-400">/</span><span class="inline-block">first-steps</span>

          

        <!-- <span class="do-hyeon-regular font-bold text-xl inline-block pt-1">#7</span><span class="inline-block px-3 text-zinc-400">/</span><span class="inline-block">Articles</span> -->

    </div>

    <div class="prose dark:prose-invert mt-12">
        <h1>Do LLMs make good privacy engineers? Yes.</h1>

        <p>Do Large Language Models make good privacy engineers? Yes, fantastically so.</p>

        <p>Clickbait aside, I’ve been benchmarking the performance of the latest LLMs on sensitive data discovery tasks, and the results are incredibly encouraging, a major leap from even a year ago.</p>

        <p></p>A common task for privacy engineers is to identify which classes of sensitive data a service handles. For example, are customer phone numbers marking their way in the company-wide Tableau instance? At scale, this can mean reviewing millions of data fields, searching for just a few findings.</p>

        <p>This seems like the sort of task an LLM should excel at. Feed the model a database schema and ask it to review it for sensitive data. Indeed, it doesn’t take much effort to get convincing-looking output for this task.</p>

        <p></p>But is it correct? Two years ago, in my initial experiments with open source models (Llama 2) these convincing outputs were rife with hallucinations and unpredictable.</p>

        <p>A lot has changed since then, and I decided to put a half dozen state of the art models to the test tagging personal data in a realistic data warehouse.</p>

        <p>Did things change? To spoil the surprise – yes – dramatically.</p>

        <p>I test two useful capabilities. First, the ability of LMs to identify sensitive data classes – emails, phone numbers, that sort of thing. Second, I test the LMs ability to determine the data subject of these tagged fields. Is this email the contact information for a customer or just a support email address for a business?</p>

        <p>Frontier models achieve >80% recall and and >80% precision on this task.</p>

        <p>Amazingly, smaller models, like the single-GPU Gemma 3, hold up this performance, achieving >60% recall and >70% precision.</p>

        <h3>Test Set Up -- Building a realistic test set</h3>

        <p>So how do we go about assembling a realistic database schema to tag?</p>

        <p></p>As a first cut, I use a trick I picked up from reviewing third party tools: use the OpenAPI specification for a SaaS API.</p>

        <p>It is</p>


        <p>I gathered a few hundred such schemas before realizing I could use just a single one: Stripe.</p>

        <p>Stripe’s APIs cover dozens of services and contain >1,000 separate <schema> objects. These schemas contain an unexpected variety of data. Did you know that flight records find their way onto Stripe’s servers and are accessible via API?</p>


    </div>

    <div class="pt-20">
    </div>
    
</div>


{% endblock %}